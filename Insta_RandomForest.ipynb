{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e926bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def import_data():\n",
    "    # Percorsi ai file JSON\n",
    "    base_paths = [\n",
    "        \"data/automated-v1.0\",\n",
    "        \"data/fake-v1.0\"\n",
    "    ]\n",
    "\n",
    "    files = {\n",
    "        \"automated\": \"automatedAccountData.json\",\n",
    "        \"nonautomated\": \"nonautomatedAccountData.json\",\n",
    "        \"fake\": \"fakeAccountData.json\",\n",
    "        \"real\": \"realAccountData.json\"\n",
    "    }\n",
    "\n",
    "    # Costruisci i percorsi completi\n",
    "    paths = {\n",
    "        \"automated\": os.path.join(base_paths[0], files[\"automated\"]),\n",
    "        \"nonautomated\": os.path.join(base_paths[0], files[\"nonautomated\"]),\n",
    "        \"fake\": os.path.join(base_paths[1], files[\"fake\"]),\n",
    "        \"real\": os.path.join(base_paths[1], files[\"real\"]),\n",
    "    }\n",
    "\n",
    "    # Leggi i file JSON come DataFrame\n",
    "    df_automated = pd.read_json(paths[\"automated\"])\n",
    "    df_nonautomated = pd.read_json(paths[\"nonautomated\"])\n",
    "    df_fake = pd.read_json(paths[\"fake\"])\n",
    "    df_real = pd.read_json(paths[\"real\"])\n",
    "\n",
    "    # Unisci tutti i DataFrame in uno solo\n",
    "    df_automated = pd.concat([df_automated, df_nonautomated], ignore_index=True)\n",
    "    df_fake = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "\n",
    "    #print(f\"\\nTotale righe: {len(df_all)}\")\n",
    "    return df_automated, df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6430a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userFollowerCount  userFollowingCount  userBiographyLength  userMediaCount  \\\n",
      "0                 25                1937                    0               0   \n",
      "1                324                4122                    0               0   \n",
      "2                 15                 399                    0               0   \n",
      "3                 14                 107                    0               1   \n",
      "4                264                4651                    0               0   \n",
      "\n",
      "   userHasProfilPic  userIsPrivate  usernameDigitCount  usernameLength  isFake  \n",
      "0                 1              1                   0              10       1  \n",
      "1                 1              0                   4              15       1  \n",
      "2                 0              0                   3              12       1  \n",
      "3                 1              0                   1              10       1  \n",
      "4                 1              0                   0              14       1  \n"
     ]
    }
   ],
   "source": [
    "df_automated, df_fake = import_data()\n",
    "\n",
    "print(df_fake.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39140e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userFollowerCount  userFollowingCount  userBiographyLength  userMediaCount  \\\n",
      "0                 25                1937                    0               0   \n",
      "1                324                4122                    0               0   \n",
      "2                 15                 399                    0               0   \n",
      "3                 14                 107                    0               1   \n",
      "4                264                4651                    0               0   \n",
      "\n",
      "   userHasProfilPic  userIsPrivate  usernameDigitCount  usernameLength  \n",
      "0                 1              1                   0              10  \n",
      "1                 1              0                   4              15  \n",
      "2                 0              0                   3              12  \n",
      "3                 1              0                   1              10  \n",
      "4                 1              0                   0              14  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: isFake, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# y = colonna target\n",
    "y = df_fake[\"isFake\"]\n",
    "\n",
    "# X = tutte le colonne tranne 'isFake'\n",
    "X = df_fake.drop(\"isFake\", axis=1)\n",
    "\n",
    "print(X[0:5])\n",
    "print(y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e20b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suddividiamo in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2159407, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdea698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters found: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuratezza sul test set: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Definizione del modello base\n",
    "rf = RandomForestClassifier(random_state=2159407)\n",
    "\n",
    "# Definizione della griglia dei parametri da ottimizzare\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],           # numero di alberi\n",
    "    \"max_depth\": [10, 20],           # profondità massima degli alberi\n",
    "    \"min_samples_split\": [2, 5],           # minimo numero di campioni per split\n",
    "    \"min_samples_leaf\": [1, 2],             # minimo numero di campioni per foglia\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]   # numero di feature da considerare per split\n",
    "}\n",
    "\n",
    "# GridSearch con 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 5-fold validation\n",
    "    n_jobs=-1,           # usa tutti i core disponibili\n",
    "    verbose=1,\n",
    "    scoring='accuracy'   # possiamo usare anche 'f1' se il dataset è sbilanciato\n",
    ")\n",
    "\n",
    "# Fit del GridSearch sui dati di training\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Parametri ottimali\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Miglior modello\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuratezza sul test set: {accuracy:.2f}\")\n",
    "print(\"Report completo:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instafake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
