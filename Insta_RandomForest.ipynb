{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bd8162",
   "metadata": {},
   "source": [
    "# Fake Account Detection\n",
    "\n",
    "Made by:\n",
    "- Francesco Pizzolato\n",
    "- Tommaso Danieli\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b1258",
   "metadata": {},
   "source": [
    "# Section 0: Data Frame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e926bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def import_data():\n",
    "    # Percorsi ai file JSON\n",
    "    base_paths = [\n",
    "        \"data/automated-v1.0\",\n",
    "        \"data/fake-v1.0\"\n",
    "    ]\n",
    "\n",
    "    files = {\n",
    "        \"automated\": \"automatedAccountData.json\",\n",
    "        \"nonautomated\": \"nonautomatedAccountData.json\",\n",
    "        \"fake\": \"fakeAccountData.json\",\n",
    "        \"real\": \"realAccountData.json\"\n",
    "    }\n",
    "\n",
    "    # Costruisci i percorsi completi\n",
    "    paths = {\n",
    "        \"automated\": os.path.join(base_paths[0], files[\"automated\"]),\n",
    "        \"nonautomated\": os.path.join(base_paths[0], files[\"nonautomated\"]),\n",
    "        \"fake\": os.path.join(base_paths[1], files[\"fake\"]),\n",
    "        \"real\": os.path.join(base_paths[1], files[\"real\"]),\n",
    "    }\n",
    "\n",
    "    # Leggi i file JSON come DataFrame\n",
    "    df_automated = pd.read_json(paths[\"automated\"])\n",
    "    df_nonautomated = pd.read_json(paths[\"nonautomated\"])\n",
    "    df_fake = pd.read_json(paths[\"fake\"])\n",
    "    df_real = pd.read_json(paths[\"real\"])\n",
    "\n",
    "    # Unisci tutti i DataFrame in uno solo\n",
    "    df_automated = pd.concat([df_automated, df_nonautomated], ignore_index=True)\n",
    "    df_fake = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "\n",
    "    \n",
    "    return df_automated, df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a6430a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of automated accounts: 1400\n",
      "Number of fake accounts: 1194\n"
     ]
    }
   ],
   "source": [
    "df_automated, df_fake = import_data()\n",
    "\n",
    "print(\"Number of automated accounts:\", len(df_automated))\n",
    "print(\"Number of fake accounts:\", len(df_fake))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fe1ed",
   "metadata": {},
   "source": [
    "# Section 1: Fake Account Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39140e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Feature sample===\n",
      "   userFollowerCount  userFollowingCount  userBiographyLength  userMediaCount  \\\n",
      "0                 25                1937                    0               0   \n",
      "1                324                4122                    0               0   \n",
      "2                 15                 399                    0               0   \n",
      "3                 14                 107                    0               1   \n",
      "4                264                4651                    0               0   \n",
      "\n",
      "   userHasProfilPic  userIsPrivate  usernameDigitCount  usernameLength  \n",
      "0                 1              1                   0              10  \n",
      "1                 1              0                   4              15  \n",
      "2                 0              0                   3              12  \n",
      "3                 1              0                   1              10  \n",
      "4                 1              0                   0              14  \n",
      "\n",
      "===Target sample===\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: isFake, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y = colonna target\n",
    "y = df_fake[\"isFake\"]\n",
    "\n",
    "# X = tutte le colonne tranne 'isFake'\n",
    "X = df_fake.drop(\"isFake\", axis=1)\n",
    "\n",
    "print(\"===Feature sample===\")\n",
    "print(X[0:5])\n",
    "\n",
    "print(\"\\n===Target sample===\")\n",
    "print(y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e20b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommy/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/tommy/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC, BorderlineSMOTE, ADASYN\n",
    "\n",
    "# Suddividiamo in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2159407, shuffle=True)\n",
    "\n",
    "\n",
    "# Applichiamo SMOTE solo al training set\n",
    "bordersmote = SMOTENC(categorical_features=[4, 5],random_state=65)\n",
    "X_train_res, y_train_res = bordersmote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085ba84",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 1.1 RandomForest implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cdea698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 126 candidates, totalling 1260 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     21\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf,\n\u001b[1;32m     22\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m   \u001b[38;5;66;03m# possiamo usare anche 'f1' se il dataset è sbilanciato\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fit del GridSearch sui dati di training\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Parametri ottimali\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Definizione del modello base\n",
    "rf = RandomForestClassifier(random_state=2159407)\n",
    "\n",
    "# Definizione della griglia dei parametri da ottimizzare\n",
    "param_grid = {\n",
    "    \"n_estimators\": [309, 310, 311, 312, 313, 314, 315],           # numero di alberi\n",
    "    \"max_depth\": [ 8, 9, 10],           # profondità massima degli alberi\n",
    "    \"min_samples_split\": [2],           # minimo numero di campioni per split\n",
    "    \"min_samples_leaf\": [2],             # minimo numero di campioni per foglia\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],   # numero di feature da considerare per split\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# GridSearch con 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,                # 5-fold validation\n",
    "    n_jobs=-1,           # usa tutti i core disponibili\n",
    "    verbose=1,\n",
    "    scoring='f1_macro'   # possiamo usare anche 'f1' se il dataset è sbilanciato\n",
    ")\n",
    "\n",
    "# Fit del GridSearch sui dati di training\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Parametri ottimali\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Miglior modello\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8ccd0",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------\n",
    "## 1.2 CatBoost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e86bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m\n\u001b[1;32m     13\u001b[0m cat \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\n\u001b[1;32m     14\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2159407\u001b[39m,\n\u001b[1;32m     15\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m search_cat \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     20\u001b[0m     cat,\n\u001b[1;32m     21\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist_cat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m987\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[43msearch_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params (CatBoost):\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_cat\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_dist_cat = {\n",
    "    'iterations': randint(300, 400),\n",
    "    'depth': randint(5, 12),\n",
    "    'learning_rate': uniform(0.05, 0.13),\n",
    "    'l2_leaf_reg': uniform(6, 8),\n",
    "    'bagging_temperature': uniform(0, 0.08)\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    random_state=2159407,\n",
    "    eval_metric='TotalF1',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "search_cat = RandomizedSearchCV(\n",
    "    cat,\n",
    "    param_distributions=param_dist_cat,\n",
    "    n_iter=500,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=987\n",
    ")\n",
    "\n",
    "search_cat.fit(X_train_res, y_train_res)\n",
    "print(\"Best params (CatBoost):\", search_cat.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea0d103",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Miglior modello CatBoost trovato dal RandomizedSearchCV\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m best_cat \u001b[38;5;241m=\u001b[39m \u001b[43msearch_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Predizioni\u001b[39;00m\n\u001b[1;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_cat\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Miglior modello CatBoost trovato dal RandomizedSearchCV\n",
    "best_cat = search_cat.best_estimator_\n",
    "\n",
    "# Predizioni\n",
    "y_pred = best_cat.predict(X_test)\n",
    "y_proba = best_cat.predict_proba(X_test)[:, 1] if len(np.unique(y_test)) == 2 else None\n",
    "\n",
    "# Metriche\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"=== Risultati CatBoost ===\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 (macro):    {f1:.4f}\")\n",
    "\n",
    "if y_proba is not None:\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"ROC AUC:       {auc:.4f}\")\n",
    "\n",
    "# Report dettagliato\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be35b1f",
   "metadata": {},
   "source": [
    "# Section 2: Automated Account Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bc698e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Feature sample===\n",
      "   userMediaCount                                   mediaLikeNumbers  \\\n",
      "0              97  [100, 78, 112, 78, 77, 111, 97, 95, 63, 83, 42...   \n",
      "1             863  [229, 331, 180, 326, 313, 157, 245, 161, 182, ...   \n",
      "2             149  [237, 254, 350, 257, 180, 172, 141, 84, 218, 8...   \n",
      "3              33  [163, 30, 92, 111, 145, 110, 81, 81, 61, 60, 6...   \n",
      "4            1000  [61, 222, 437, 829, 681, 440, 920, 256, 1017, ...   \n",
      "\n",
      "                                 mediaCommentNumbers  \\\n",
      "0  [5, 2, 10, 0, 3, 2, 2, 2, 4, 0, 0, 6, 6, 0, 2,...   \n",
      "1  [3, 2, 3, 4, 7, 2, 0, 6, 2, 2, 1, 9, 2, 0, 2, ...   \n",
      "2  [12, 16, 37, 11, 3, 4, 2, 4, 5, 1, 1, 2, 3, 3,...   \n",
      "3  [2, 2, 7, 14, 17, 3, 2, 5, 2, 1, 5, 5, 8, 1, 4...   \n",
      "4  [4, 0, 13, 9, 9, 6, 16, 4, 25, 6, 3, 4, 16, 10...   \n",
      "\n",
      "                            mediaCommentsAreDisabled  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                 mediaHashtagNumbers  \\\n",
      "0  [10, 10, 12, 10, 13, 13, 10, 12, 10, 11, 11, 1...   \n",
      "1  [8, 11, 14, 17, 12, 10, 13, 14, 14, 11, 10, 11...   \n",
      "2  [25, 25, 25, 25, 15, 15, 15, 5, 15, 10, 10, 10...   \n",
      "3  [0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 14, 14, 0, 0...   \n",
      "4  [4, 1, 2, 3, 3, 0, 0, 1, 0, 2, 1, 2, 3, 1, 1, ...   \n",
      "\n",
      "                                    mediaUploadTimes  \\\n",
      "0  [1540847457, 1540744841, 1538410400, 153729214...   \n",
      "1  [1542664246, 1542569444, 1542564418, 154211928...   \n",
      "2  [1543220394, 1542972220, 1542868998, 154278889...   \n",
      "3  [1543886933, 1543793413, 1543704343, 154344770...   \n",
      "4  [1543939920, 1543699089, 1543187756, 154264414...   \n",
      "\n",
      "                                mediaHasLocationInfo  userFollowerCount  \\\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               1612   \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               3028   \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...               5213   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              12423   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...               9496   \n",
      "\n",
      "   userFollowingCount  userHasHighlighReels  userHasExternalUrl  \\\n",
      "0                7108                     0                   1   \n",
      "1                 912                     1                   0   \n",
      "2                1157                     1                   1   \n",
      "3                1763                     0                   0   \n",
      "4                2412                     1                   0   \n",
      "\n",
      "   userTagsCount  userBiographyLength  usernameLength  usernameDigitCount  \n",
      "0             36                  133              12                   0  \n",
      "1             77                   99              11                   0  \n",
      "2             56                  120              18                   0  \n",
      "3              2                   55              13                   0  \n",
      "4             91                   33               8                   0  \n",
      "\n",
      "===Target sample===\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: automatedBehaviour, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y = colonna target\n",
    "y = df_automated[\"automatedBehaviour\"]\n",
    "\n",
    "# X = tutte le colonne tranne 'automatedBehaviour'\n",
    "X = df_automated.drop(\"automatedBehaviour\", axis=1)\n",
    "\n",
    "print(\"===Feature sample===\")\n",
    "print(X[0:5])\n",
    "\n",
    "print(\"\\n===Target sample===\")\n",
    "print(y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3e8b524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===LCR Column Sample===\n",
      " 0    22.432773\n",
      "1    35.985014\n",
      "2    35.000000\n",
      "3    13.613924\n",
      "4    44.704881\n",
      "Name: LCR, dtype: float64\n",
      "===FFR Column Sample===\n",
      " 0    0.226787\n",
      "1    3.320175\n",
      "2    4.505618\n",
      "3    7.046512\n",
      "4    3.936982\n",
      "Name: FFR, dtype: float64\n",
      "===userHasNoMedia Column Sample===\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: userHasNoMedia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add the features derived from the base ones\n",
    "\n",
    "# Average recent media like to comment ratio (LCR)\n",
    "def compute_lcr(likes, comments):\n",
    "\t# likes and comments are list-like in the dataset, we need to compute totals\n",
    "\ttotal_likes = sum(likes) \n",
    "\ttotal_comments = sum(comments) \n",
    "\tif total_comments == 0:\n",
    "\t\treturn 0.0\n",
    "\treturn total_likes / total_comments\n",
    "\n",
    "#Average recent media like to comment ratio (LCR)\n",
    "X['LCR'] = X.apply(lambda row: compute_lcr(row['mediaLikeNumbers'], row['mediaCommentNumbers']), axis=1)\n",
    "df_automated['LCR'] = X['LCR']\n",
    "print('===LCR Column Sample===\\n',X['LCR'][:5])\n",
    "\n",
    "#Follower to following ratio (FFR).\n",
    "X['FFR'] = X.apply(lambda row: row['userFollowerCount'] / row['userFollowingCount'] if row['userFollowingCount']!= 0 else 0, axis=1)\n",
    "df_automated['FFR'] = X['FFR']\n",
    "print('===FFR Column Sample===\\n',X['FFR'][:5])\n",
    "\n",
    "#User has no media (binary feature, 1 if true, 0 otherwise)\n",
    "X['userHasNoMedia'] = X.apply(lambda row: 1 if row['userMediaCount']==0 else 0, axis=1)\n",
    "df_automated['userHasNoMedia'] = X['userHasNoMedia']\n",
    "print(\"===userHasNoMedia Column Sample===\\n\",X['userHasNoMedia'][:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "254d26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming list feature: mediaLikeNumbers\n",
      "Transforming list feature: mediaCommentNumbers\n",
      "Transforming list feature: mediaCommentsAreDisabled\n",
      "Transforming list feature: mediaHashtagNumbers\n",
      "Transforming list feature: mediaUploadTimes\n",
      "Transforming list feature: mediaHasLocationInfo\n",
      "All list features successfully transformed (6 columns).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/83f1sh6d6z14shhw1nkwttxr0000gn/T/ipykernel_2397/4060635770.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  has_lists = df_out.applymap(lambda x: isinstance(x, list)).any().any()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_list_features(df):\n",
    "    df_out = df.copy()\n",
    "    list_columns = []\n",
    "\n",
    "    # Trova le colonne che contengono almeno una lista\n",
    "    for col in df_out.columns:\n",
    "        if df_out[col].apply(lambda x: isinstance(x, list)).any():\n",
    "            print(f\"Transforming list feature: {col}\")\n",
    "            list_columns.append(col)\n",
    "            df_out[col] = df_out[col].apply(\n",
    "                lambda x: float(np.mean(x)) if isinstance(x, list) and len(x) > 0\n",
    "                else (np.nan if isinstance(x, list) else x)\n",
    "            )\n",
    "\n",
    "    # Controllo finale: verifico se rimangono liste\n",
    "    has_lists = df_out.applymap(lambda x: isinstance(x, list)).any().any()\n",
    "    if not has_lists:\n",
    "        print(f\"All list features successfully transformed ({len(list_columns)} columns).\")\n",
    "    else:\n",
    "        print(\"Warning: some list-like values remain after transformation!\")\n",
    "\n",
    "    return df_out\n",
    "\n",
    "df_automated = transform_list_features(df_automated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6140d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===New Feature sample===\n",
      "   userMediaCount  mediaLikeNumbers  mediaCommentNumbers  \\\n",
      "0              97         55.041237             2.453608   \n",
      "1             863         61.212051             1.701043   \n",
      "2             149         70.939597             2.026846   \n",
      "3              33         65.181818             4.787879   \n",
      "4            1000        160.267000             3.585000   \n",
      "\n",
      "   mediaCommentsAreDisabled  mediaHashtagNumbers  mediaUploadTimes  \\\n",
      "0                       0.0            13.886598      1.509952e+09   \n",
      "1                       0.0             4.115875      1.467057e+09   \n",
      "2                       0.0            10.302013      1.521111e+09   \n",
      "3                       0.0             2.121212      1.536461e+09   \n",
      "4                       0.0             4.008000      1.448682e+09   \n",
      "\n",
      "   mediaHasLocationInfo  userFollowerCount  userFollowingCount  \\\n",
      "0              0.979381               1612                7108   \n",
      "1              0.505214               3028                 912   \n",
      "2              0.248322               5213                1157   \n",
      "3              0.000000              12423                1763   \n",
      "4              0.269000               9496                2412   \n",
      "\n",
      "   userHasHighlighReels  userHasExternalUrl  userTagsCount  \\\n",
      "0                     0                   1             36   \n",
      "1                     1                   0             77   \n",
      "2                     1                   1             56   \n",
      "3                     0                   0              2   \n",
      "4                     1                   0             91   \n",
      "\n",
      "   userBiographyLength  usernameLength  usernameDigitCount        LCR  \\\n",
      "0                  133              12                   0  22.432773   \n",
      "1                   99              11                   0  35.985014   \n",
      "2                  120              18                   0  35.000000   \n",
      "3                   55              13                   0  13.613924   \n",
      "4                   33               8                   0  44.704881   \n",
      "\n",
      "        FFR  userHasNoMedia  \n",
      "0  0.226787               0  \n",
      "1  3.320175               0  \n",
      "2  4.505618               0  \n",
      "3  7.046512               0  \n",
      "4  3.936982               0  \n",
      "\n",
      "===Target sample===\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: automatedBehaviour, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# y = colonna target\n",
    "y = df_automated[\"automatedBehaviour\"]\n",
    "\n",
    "# X = tutte le colonne tranne 'automatedBehaviour'\n",
    "X = df_automated.drop(\"automatedBehaviour\", axis=1)\n",
    "\n",
    "print(\"===New Feature sample===\")\n",
    "print(X[0:5])\n",
    "\n",
    "print(\"\\n===Target sample===\")\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "99b5d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_costs = {\n",
    "    \"userMediaCount\": 2,\n",
    "    \"userFollowerCount\": 4,\n",
    "    \"userFollowingCount\": 4,\n",
    "    \"userHasHighlighReels\": 2,\n",
    "    \"userHasExternalUrl\": 2,\n",
    "    \"userTagsCount\": 3,\n",
    "    \"mediaHashtagNumbers\": 2,\n",
    "    \"userHasNoMedia\": 1,\n",
    "    \"LCR\": 2, #Like to Comment Ratio\n",
    "    \"FFR\": 4 #Followers to Following Ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "490ae5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_score(precision, recall):\n",
    "    if (5 * precision + recall) == 0:\n",
    "        return 0\n",
    "    return 5 * (precision * recall) / (5 * precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71cab978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(precision, recall, features):\n",
    "    # Calculate total feature cost\n",
    "    total_cost = 0\n",
    "    for f in features:\n",
    "        total_cost += feature_costs.get(f, 0)\n",
    "    \n",
    "    # Compute fitness using given formula\n",
    "    fitness = f2_score(precision, recall) - 2 * total_cost\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c58c6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def genetic_algorithm(X, PopulationSize=10, NumberofGenerations=20, MutationRate=0.1):\n",
    "    features = list(feature_costs.keys())\n",
    "    n_features = len(features)\n",
    "\n",
    "    # Initialize population as binary masks (1 = selected, 0 = not)\n",
    "    population = [np.random.randint(0, 2, n_features).tolist() for _ in range(PopulationSize)]\n",
    "\n",
    "    for generation in range(NumberofGenerations):\n",
    "        # Step 2: Evaluate fitness of each individual\n",
    "        fitness_values = []\n",
    "        for individual in population:\n",
    "            selected = [features[i] for i in range(n_features) if individual[i] == 1]\n",
    "            \n",
    "            # Example: replace these placeholders with model-based precision/recall\n",
    "            precision = random.uniform(0.5, 0.9)\n",
    "            recall = random.uniform(0.5, 0.9)\n",
    "            \n",
    "            fit = fitness_function(precision, recall, selected)\n",
    "            fitness_values.append(fit)\n",
    "\n",
    "        # Step 3: Select best individual (elitism)\n",
    "        best_index = np.argmax(fitness_values)\n",
    "        best_individual = population[best_index]\n",
    "\n",
    "        # Step 4: Select one random individual\n",
    "        random_individual = random.choice(population)\n",
    "\n",
    "        # Step 5: Perform crossover (tournament selection for rest)\n",
    "        new_population = [best_individual, random_individual]\n",
    "        while len(new_population) < PopulationSize:\n",
    "            parents = random.sample(population, 2)\n",
    "            crossover_point = random.randint(1, n_features - 1)\n",
    "            child = parents[0][:crossover_point] + parents[1][crossover_point:]\n",
    "            new_population.append(child)\n",
    "\n",
    "        # Step 6: Mutate one individual with MutationRate\n",
    "        if random.random() < MutationRate:\n",
    "            ind_to_mutate = random.choice(new_population)\n",
    "            mutation_point = random.randint(0, n_features - 1)\n",
    "            ind_to_mutate[mutation_point] = 1 - ind_to_mutate[mutation_point]\n",
    "\n",
    "        # Step 7: Update population\n",
    "        population = new_population\n",
    "\n",
    "        print(f\"Generation {generation+1}/{NumberofGenerations} - Best Fitness: {max(fitness_values):.3f}\")\n",
    "\n",
    "    # Step 9: Form ReducedDataset using best individual's features\n",
    "    final_selected = [features[i] for i in range(n_features) if best_individual[i] == 1]\n",
    "    ReducedDataset = X[final_selected]\n",
    "    \n",
    "    return ReducedDataset, final_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2e153681",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2159407, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20db0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 126 candidates, totalling 1260 fits\n",
      "Best parameters found: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 311}\n",
      "Accuracy on Test Set: 0.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.93      0.94      0.94       132\n",
      "        Fake       0.95      0.94      0.94       148\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Definizione del modello base\n",
    "rf = RandomForestClassifier(random_state=2159407)\n",
    "\n",
    "# Definizione della griglia dei parametri da ottimizzare\n",
    "param_grid = {\n",
    "    \"n_estimators\": [309, 310, 311, 312, 313, 314, 315],           # numero di alberi\n",
    "    \"max_depth\": [ 8, 9, 10],           # profondità massima degli alberi\n",
    "    \"min_samples_split\": [2],           # minimo numero di campioni per split\n",
    "    \"min_samples_leaf\": [2],             # minimo numero di campioni per foglia\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],   # numero di feature da considerare per split\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# GridSearch con 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,                # 5-fold validation\n",
    "    n_jobs=-1,           # usa tutti i core disponibili\n",
    "    verbose=1,\n",
    "    scoring='f1_macro'   # possiamo usare anche 'f1' se il dataset è sbilanciato\n",
    ")\n",
    "\n",
    "# Fit del GridSearch sui dati di training\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Parametri ottimali\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Miglior modello\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666b451",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
